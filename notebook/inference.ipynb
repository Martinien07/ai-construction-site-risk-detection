{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e552bc",
   "metadata": {},
   "source": [
    "Ce code permet de faire l'interférence\n",
    "\n",
    "Après vous pouvez utiliser l'autre pour la visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f48e2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Ajouter le chemin de ton projet local en tête\n",
    "sys.path.insert(0, r\"D:\\ETUDEµ\\CITE\\ETAPE4\\PROJET DE FIN DE SESSION\\TOURMANT 1\")\n",
    "\n",
    "from db.pool import init_pools\n",
    "\n",
    "from inference.video_inference_prod import run_video_production\n",
    "\n",
    "init_pools()\n",
    "\n",
    "\n",
    "run_video_production(\"data/test.mp4\",site_id=1, camera_id=1,model_path=\"../models/best_yolo11x.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233e7803",
   "metadata": {},
   "source": [
    "Pour faire les visualisation de la video et objet détectecté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a96b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "\n",
    "# Ajouter le chemin de ton projet local en tête\n",
    "sys.path.insert(0, r\"D:\\ETUDEµ\\CITE\\ETAPE4\\PROJET DE FIN DE SESSION\\TOURMANT 1\")\n",
    "\n",
    "from inference.persistence import get_detections_for_frame\n",
    "\n",
    "\n",
    "def replay_video_with_boxes(\n",
    "    video_path: str,\n",
    "    camera_id: int,\n",
    "    start_time,\n",
    "    fps: int = 25,\n",
    "    slow_factor: float = 1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Replay vidéo avec affichage des bounding boxes\n",
    "    STOCKÉES EN BASE (aucune détection YOLO).\n",
    "\n",
    "    slow_factor:\n",
    "        1.0 = normal\n",
    "        2.0 = 2x plus lent\n",
    "        4.0 = 4x plus lent\n",
    "    \"\"\"\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_duration = timedelta(seconds=1 / fps)\n",
    "\n",
    "    current_time = start_time\n",
    "    frame_idx = 0\n",
    "\n",
    "    wait_ms = int((1000 / fps) * slow_factor)\n",
    "\n",
    "    print(f\"[INFO] Replay fps={fps} | slow_factor={slow_factor}\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        next_time = current_time + frame_duration\n",
    "\n",
    "        detections = get_detections_for_frame(\n",
    "            camera_id=camera_id,\n",
    "            start_ts=current_time,\n",
    "            end_ts=next_time\n",
    "        )\n",
    "\n",
    "        for det in detections:\n",
    "            x1 = int(det[\"bbox_x\"])\n",
    "            y1 = int(det[\"bbox_y\"])\n",
    "            x2 = int(x1 + det[\"bbox_w\"])\n",
    "            y2 = int(y1 + det[\"bbox_h\"])\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f'{det[\"object_class\"]} #{det[\"track_id\"]}',\n",
    "                (x1, y1 - 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 255, 0),\n",
    "                1\n",
    "            )\n",
    "\n",
    "        cv2.imshow(\"Replay detections\", frame)\n",
    "\n",
    "        if cv2.waitKey(wait_ms) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "        current_time = next_time\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03defeb6",
   "metadata": {},
   "source": [
    "Test. Pour vérifier les objets détecter . Il faut renseigné la date et l'heure du debut et de fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0b6862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Replay fps=25 | slow_factor=1.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "video_start_time = datetime.strptime(\n",
    "    \"2026-01-18 20:31:40\",\n",
    "    \"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "from db.pool import init_pools\n",
    "\n",
    "init_pools()\n",
    "replay_video_with_boxes(\n",
    "    \"data/test.mp4\",\n",
    "    camera_id=1,\n",
    "    start_time=video_start_time,\n",
    "    fps=25,\n",
    "    slow_factor=1.0\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae8a816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MEHOUN MARTINIEN\\AppData\\Local\\Temp\\ipykernel_24800\\930000970.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"../models/best_yolo11x.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucune info de classes trouvée dans le modèle.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Charger le modèle\n",
    "model = torch.load(\"../models/best_yolo11x.pt\")\n",
    "\n",
    "# Vérifier si les classes sont dans l'objet\n",
    "if hasattr(model, 'names'):\n",
    "    print(\"Classes :\", model.names)\n",
    "elif hasattr(model, 'model') and hasattr(model.model, 'names'):\n",
    "    print(\"Classes :\", model.model.names)\n",
    "else:\n",
    "    print(\"Aucune info de classes trouvée dans le modèle.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab3a7016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Hardhat', 1: 'Mask', 2: 'NO-Hardhat', 3: 'NO-Mask', 4: 'NO-Safety Vest', 5: 'Person', 6: 'Safety Cone', 7: 'Safety Vest', 8: 'machinery', 9: 'utility pole', 10: 'vehicle'}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"../models/best_yolo11x.pt\")\n",
    "print(model.names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
